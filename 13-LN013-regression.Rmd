## Lecture Notes Week 13: Inference for Two Quantitative Variables


\setstretch{1}

### Summary measures and plots for two quantitative variables. {-}

Scatterplot:
	
* Form: linear or non-linear?

* Direction: positive or negative?

* Strength: how clear is the pattern between the two variables?

* Outliers: points that are far from the pattern or bulk of the data

    * Influential points: outliers that are extreme in the x-\ variable.

\setstretch{1.5}

The summary measures for two quantitative variables are:

* ____________________________, interpreted as 

\vspace{0.6in}

* ____________________________, which measures the 

\vspace{0.6in}

* ____________________________, interpreted as

\vspace{0.6in}

\setstretch{1}

* Least-squares regression line: $\hat{y}=b_0+b_1\times x$ (put y and x in the context of the problem)

\setstretch{1.5}

Notation:

* Population slope: 

* Population correlation:

* Sample slope:

* Sample correlation:

\setstretch{1}

Example:  Oceanic temperature is important for sea life.  The California Cooperative Oceanic Fisheries Investigations has measured several variables on the Pacific Ocean for more than 70 years hoping to better understand weather patterns and impacts on ocean life.  For this example, we will look at the most recent 100 measurements of salt water salinity (measured in PSUs or practical salinity units) and the temperature of the ocean measured in degrees Celsius. Is there evidence that water temperature tends to decrease with higher levels of salinity.

```{r, echo=FALSE}
bottle <- read.csv("data/bottle.csv")
bottles <- bottle %>%
    na.omit()
set.seed(1)
water<-bottles[c(sample((1:814247), 100, replace=FALSE)),]
```

```{r, echo=TRUE, warning=FALSE}
water %>% # Pipe data set into...
ggplot(aes(x = Salnty, y = T_degC))+  # Specify variables
  geom_point(alpha=0.5) +  # Add scatterplot of points
  labs(x = "salinity (PSUs)",  # Label x-axis
       y = "temperature (C)",  # Label y-axis
       title = "Scatterplot of Pacific Ocean Salinity vs Temperature") + 
               # Be sure to title your plots
  geom_smooth(method = "lm", se = FALSE)  # Add regression line

```

Describe the four characteristics of the scatterplot:

\vspace{1in}

Linear model output:

```{r, echo=TRUE}
lm.water <- lm(T_degC~Salnty, data=water) # lm(response~explanatory)
round(summary(lm.water)$coefficients, 3)
```
\newpage

Correlation:

```{r, echo=TRUE}
cor(T_degC~Salnty, data=water)
```
Write the least squares equation of the line in context of the problem:

\vspace{0.5in}

Interpret the value of slope in the context of the problem:

\vspace{0.5in}

Report and describe the correlation value:

\vspace{0.5in}

Calculate and interpret the coefficient of determination:

\vspace{0.8in}

### Hypothesis Testing {-}

Conditions:

* Independence:

\vspace{0.3in}

* Linear relationship:

\vspace{0.3in}

Null hypothesis assumes “no effect”, “no difference”, “nothing interesting happening”, etc.

\rgi Always of form:  “parameter” = null value

$H_0:$

\vspace{0.5in}

$H_A:$

\vspace{0.5in}

* Research question determines the alternative hypothesis.

Write the null and alternative for the ocean study:

In words: 

$H_0:$

\vspace{0.5in}

$H_A:$

\vspace{0.5in}

In notation:

$H_0:$

\vspace{0.2in}

$H_A:$

\vspace{0.2in}

#### Simulation-based method {-}

* Simulate many samples assuming $H_0: \beta_1 = 0$ or $H_0: \rho =0$

    * Write the response variable values on cards

    * Hold the explanatory variable values constant
    
    * Shuffle a new response variable to an explanatory variable
    
    * Plot the shuffled data points to find the least squares line of regression

    * Calculate and plot the simulated slope or correlation from each simulation

    * Repeat 1000 times (simulations) to create the null distribution

    * Find the proportion of simulations at least as extreme as $b_1$ or $r$
    
To test slope:    
```{r, echo=TRUE}
set.seed(216)
regression_test(T_degC ~ Salnty, # response ~ explanatory
               data = water, # Name of data set
               direction = "less", # Sign in alternative ("greater", "less", "two-sided")
               summary_measure = "slope", # "slope" or "correlation"
               as_extreme_as = -5.514, # Observed slope or correlation
               number_repetitions = 1000) # Number of simulated samples for null distribution
```
To test correlation:
```{r, echo=TRUE, eval=TRUE}
set.seed(216)
regression_test(T_degC~Salnty, # response ~ explanatory
               data = water, # Name of data set
               direction = "less", # Sign in alternative ("greater", "less", "two-sided")
               summary_measure = "correlation", # "slope" or "correlation"
               as_extreme_as = -0.659, # Observed slope or correlation
               number_repetitions = 1000) # Number of simulated samples for null distribution
```

Explain why the null distribution is centered at the value of zero:

\vspace{0.5in}
\newpage

Interpretation of the p-value:

* Statement about probability or proportion of samples

* Statistic (summary measure and value)
    
* Direction of the alternative 
    
* Null hypothesis (in context) 

\vspace{0.8in}

Conclusion: 

* Amount of evidence
    
* Parameter of interest 
    
* Direction of the alternative hypothesis

\vspace{0.6in}

#### Theory-based method{-}

Conditions:

\setstretch{1.5}

* Linearity (for both simulation-based and theory-based methods): the data should follow a linear trend.

    * Check this assumption by examining the ____________________________ of the two variables, and ____________________________________________. The pattern in the residual plot should display a horizontal line.
    
* Independence (for both simulation-based and theory-based methods)

    * One______________________________for an observational unit has no impact on  ________________________________.

* Constant variability (for theory-based methods only): the variability of points around the least squares line remains roughly constant

    * Check this assumption by examining the ________________________________. The variability in the residuals around zero should be approximately the same for all fitted values.

\newpage

* Nearly normal residuals (for theory-based methods only): residuals must be nearly normal

    * Check this assumption by examining a _________________________________, which should appear approximately normal
    
\setstretch{1}
    
Example:  

It is a generally accepted fact that the more carats a diamond has, the more expensive that diamond will be. The question is, how much more expensive? Data on thousands of diamonds were collected for this data set. We will only look at one type of cut (“Ideal”) and diamonds less than 1 carat. Does the association between carat size and price have a linear relationship for these types of diamonds? What can we state about the association between carat size and price? 

```{r, echo=FALSE}
IdealDiamonds <- read.csv("data/diamonds.csv") %>%
  filter(cut == 'Ideal') %>% #Filters the data set to the same cut
  filter(carat < 1)
set.seed(216)
Diamonds <- IdealDiamonds %>%
  sample(1000)
```

Scatterplot:
```{r, echo=TRUE, warning=FALSE}
Diamonds %>% # Pipe data set into...
    ggplot(aes(x = carat, y = price))+  # Specify variables
    geom_point(alpha=0.5) +  # Add scatterplot of points
    labs(x = "carat",  # Label x-axis
       y = "price ($)",  # Label y-axis
       title = "Scatterplot of Diamonds Carats vs Price") + 
               # Be sure to title your plots
    geom_smooth(method = "lm", se = FALSE)  # Add regression line

```
\newpage

Diagnostic plots:
```{r}
lm.diamond <- lm(price~carat, data=Diamonds) #lm(response~explanatory)
par(mfrow=c(1,2)) # Set graphics parameters to plot 2 plots in 1 row
plot(lm.diamond, which=1) # Residual vs fitted values
hist(lm.diamond$resid, xlab="Residuals", ylab="Frequency",
     main = "Histogram of Residuals") # Histogram of residuals
```

    
Check the conditions for the ocean data:

Scatterplot:
```{r, echo=TRUE, warning=FALSE}
water %>% # Pipe data set into...
ggplot(aes(x = Salnty, y = T_degC))+  # Specify variables
  geom_point(alpha=0.5) +  # Add scatterplot of points
  labs(x = "salinity (PSUs)",  # Label x-axis
       y = "temperature (C)",  # Label y-axis
       title = "Scatterplot of Pacific Ocean Salinity vs Temperature") + 
               # Be sure to title your plots
  geom_smooth(method = "lm", se = FALSE)  # Add regression line

```

\newpage

Diagnostic plots:
```{r}
par(mfrow=c(1,2)) # Set graphics parameters to plot 2 plots in 1 row
plot(lm.water, which=1) # Residual vs fitted values
hist(lm.water$resid, xlab="Residuals", ylab="Frequency",
     main = "Histogram of Residuals") # Histogram of residuals
```

Like with paired data the $t$-distribution can be used to model slope and correlation. 

\setstretch{1.5}

* For two quantitative variables we use the ______-distribution
with _____________________ degrees of freedom to approximate the sampling distribution.

\setstretch{1}

Theory-based test:

* Calculate the standardized statistic

* Find the area under the $t$-distribution with $n - 2$ df at least as extreme as the standardized statistic

Equation for the standardized slope:

\vspace{0.8in}

Calculate the standardized slope for the ocean data

\vspace{1in}

```{r, pvalueoce, echo = F}

x <- seq(-4, 4, length=100)
hx<-dt(x, 98)
degf <- 98

plot(x, hx, type="l", lty=1, lwd=3, xlab="",
  ylab="Density", main="t-distribution with 98 df")

```

Interpret the standardized statistic:

\vspace{0.8in}

To find the theory-based p-value:

```{r, echo=TRUE}
lm.water <- lm(T_degC~Salnty, data=water) # lm(response~explanatory)
summary(lm.water)$coefficients
```

or

```{r, echo=TRUE}
pt(-8.670, df = 98, lower.tail=TRUE)
```
### Confidence interval {-}

To estimate the true slope (or true correlation) we will create a confidence interval.

#### Simulation-based method{-}

* Write the explanatory and response value pairs on cards

* Sample pairs with replacement $n$ times

* Plot the resampled data points to find the least squares line of regression
    
* Calculate and plot the simulated slope (or correlation) from each simulation

* Repeat 1000 times (simulations) to create the bootstrap distribution

* Find the cut-offs for the middle X\% (confidence level) in a bootstrap distribution.

Returning to the ocean example, we will estimate the true slope between salinity and temperature of the Pacific Ocean.

```{r, echo = TRUE}
set.seed(216)
regression_bootstrap_CI(T_degC~Salnty, # response ~ explanatory
   data = water, # Name of data set
   confidence_level = 0.95, # Confidence level as decimal
   summary_measure = "slope", # Slope or correlation
   number_repetitions = 1000) # Number of simulated samples for bootstrap distribution
```

Confidence interval interpretation:

* How confident you are (e.g., 90\%, 95\%, 98\%, 99\%)
    
* Parameter of interest
    
* Calculated interval
    
* Order of subtraction when comparing two groups

\vspace{0.8in}

Now we will estimate the true correlation between salinity and temperature of the Pacific Ocean.

```{r, echo = TRUE}
set.seed(216)
regression_bootstrap_CI(T_degC~Salnty, # response ~ explanatory
   data = water, # Name of data set
   confidence_level = 0.95, # Confidence level as decimal
   summary_measure = "correlation", # Slope or correlation
   number_repetitions = 1000) # Number of simulated samples for bootstrap distribution
```

Confidence interval interpretation:

* How confident you are (e.g., 90\%, 95\%, 98\%, 99\%)
    
* Parameter of interest
    
* Calculated interval
    
* Order of subtraction when comparing two groups

\vspace{0.8in}

#### Theory-based method {-}

* Calculate the interval centered at the sample statistic

\rgi $\text{statistic} \pm \text{margin of error}$

\vspace{0.6in}


```{r, echo=TRUE}
lm.water <- lm(T_degC~Salnty, data=water) # lm(response~explanatory)
round(summary(lm.water)$coefficients, 3)
```

Using the ocean data, calculate the confidence interval for the true slope.

\vspace{1in}

\newpage
