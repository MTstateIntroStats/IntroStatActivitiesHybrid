## Guided Activity 11:  Color Interference

<!-- Data set source: http://users.stat.ufl.edu/~winner/datasets.html -->
<!-- Data simulated to match means and SDs in article. -->

\setstretch{1}

### Learning outcomes

* Given a research question involving paired differences, construct the null and alternative hypotheses
  in words and using appropriate statistical symbols.
  
* Describe and perform a theory-based hypothesis test for a paired mean difference.

* Interpret and evaluate a p-value for a theory-based hypothesis test for a paired mean difference.

* Use theory-based methods to find a confidence interval for a paired mean difference.

* Interpret a confidence interval for a paired mean difference.

* Use a confidence interval to determine the conclusion of a hypothesis test.

### Terminology review

In today's activity, we will analyze paired quantitative data using theory-based methods. Some terms covered in this activity are:

* Paired data

* Mean difference

* Independent observational units

* Normality

* $t$-distribution

* Degrees of freedom

* T-score

To review these concepts, see Chapter 18 in the textbook.

### Paired vs. Independent Samples

For each of the following scenarios, determine whether the samples are paired or independent.

1. Researchers interested in studying the effect of a medical treatment on insulin rate measured insulin rates of 30 patients before and after the medical treatment.
\vspace{0.3in}

2.  A university is planning to bring emotional support animals to campus during finals week and wants to determine which type of animals are more effective at calming students.  Anxiety levels will be measured before and after each student interacts with either a dog or a cat.  The university will then compare change in anxiety levels between the 'dog' people and the 'cat' people.
\vspace{0.3in}

3.  An industry leader is investigating a possible wage gap between male and non-male employees.  Twenty companies within the industry are randomly selected and the average salary for all males and non-males in mid-management positions is recorded for each company.
\vspace{0.3in}

### Color Interference

The abstract of the article "Studies of interference in serial verbal reactions" in the _Journal of Experimental Psychology_ [@stroop1935] reads:

> In this study pairs of conflicting stimuli, both being inherent aspects of the same symbols, were presented simultaneously (a name of one color printed in the ink of another color---a word stimulus and a color stimulus).
> The difference in time for reading the words printed in colors and the same words printed in black is the measure of interference of color stimuli upon reading words. ...
> The interference of conflicting color stimuli upon the time for reading 100 words (each word naming a color unlike the ink-color of its print) caused an increase of 2.3 seconds or 5.6% over the normal time for reading the same words printed in black.

The article reports on the results of a study in which seventy college undergraduates were given forms with 100 names of colors written in black ink, and the same 100 names of colors written in another color (i.e., the word purple written in green ink).  The total time (in seconds) for reading the 100 words printed in black, and the total time (in seconds) for reading the 100 words printed in different colors were recorded for each subject. The order in which the forms (black or color) were given was randomized to the subjects. Does printing the name of colors in a different color increase the time it takes to read the words?  Use color $-$ black as the order of subtraction.

#### Identify the scenario {-}

1. Should these observations be considered paired or independent?  Explain your answer.
\vspace{0.5in}

<!-- 2.  Based on your answer to question 1, is the appropriate summary measure to be used to analyze these data the difference in mean times or the mean difference in times? -->
<!-- \vspace{0.25in} -->

#### Ask a research question {-}

2. Write out the null hypothesis in words, in the context of this study.  

\vspace{0.8in}

3. Write out the alternative hypothesis in proper notation for this study.

\vspace{0.5in}

In general, the sampling distribution for a sample mean, $\bar{x}$, based on a sample of size $n$ from a population with a true mean $\mu$ and true standard deviation $\sigma$ can be modeled using a Normal distribution when certain conditions are met.

Conditions for the sampling distribution of $\bar{x}$ to follow an approximate Normal distribution:

* **Independence**: The sampleâ€™s observations are independent.  For paired data, that means each pairwise difference should be independent.

* **Normality**: The data should be approximately normal or the sample size should be large.

    - $n < 30$: If the sample size $n$ is less than 30 and the distribution of the data is approximately normal with no clear outliers in the data, then we typically assume the data come from a nearly normal distribution to satisfy the condition.

    - $30 \leq n < 100$: If the sample size $n$ is betwe 30 and 100 and there are no particularly extreme outliers in the data, then we typically assume the sampling distribution of $\bar{x}$ is nearly normal, even if the underlying distribution of individual observations is not.
    
    - $n \geq 100$: If the sample size $n$ is at least 100 (regardless of the presence of skew or outliers), we typically assume the sampling distribution of $\bar{x}$ is nearly normal, even if the underlying distribution of individual observations is not.
 
```{r tdist, echo = F, fig.cap = "Comparison of the standard Normal vs t-distribution with various degrees of freedom"}
# Display the Student's t distributions with various
# degrees of freedom and compare to the normal distribution

x <- seq(-4, 4, length=100)
hx <- dnorm(x)

degf <- c(1, 3, 8)
colors <- c("red", "blue", "chartreuse4", "black")
type <- c(3, 4, 2, 1)
labels <- c("df=1", "df=3", "df=8", "normal")

plot(x, hx, type="l", lty=1, lwd=3, xlab="x value",
  ylab="Density", main="Comparison of t Distributions")

for (i in 1:4){
  lines(x, dt(x,degf[i]), lwd=3, col=colors[i], lty = type[i])
}

legend("topright", inset=.05, title="Distributions",
  labels, lwd=2, lty=type, col=colors)
```
    
 
Like we saw in Chapter **5**, we will not know the values of the parameters and must use the sample data to estimate them.  Unlike with proportions, in which we only needed to estimate the population proportion, $\pi$, quantitative sample data must be used to estimate both a population mean $\mu$ and a population standard deviation $\sigma$. This additional uncertainty will require us to use a theoretical distribution that is just a bit wider than the Normal distribution. Enter the **$t$-distribution**!


As you can seen from Figure \@ref(fig:tdist), the $t$-distributions (dashed and dotted lines) are centered at 0 just like a standard Normal distribution (solid line), but are slightly wider.  The variability of a $t$-distribution depends on its degrees of freedom, which is calculated from the sample size of a study.  (For a single sample of $n$ observations or paired differences, the degrees of freedom is equal to $n-1$.) Recall from previous classes that larger sample sizes tend to result in narrower sampling distributions.  We see that here as well.  The larger the sample size, the larger the degrees of freedom, the narrower the $t$-distribution.  (In fact, a $t$-distribution with infinite degrees of freedom actually IS the standard Normal distribution!)


#### Summarize and visualize the data {-}

Since the original data from the study are not available, we simulated data to match the means and standard deviations reported in the article. We will use these simulated data in the analysis below.

<!-- Means of original data: 43.30 s (color), 41.00 (black) -->
<!-- SDs of original data: 6.15 s (color) 4.84 (black) -->

The following code plots each subject's time to read the colored words (above) and time to read the black words (below) connected by a grey line, a histogram of the differences in time to read words between the two conditions, and a boxplot displaying the pairwise differences in time (color $-$ black).

```{r, echo=TRUE, eval=TRUE}
color <- read.csv("https://math.montana.edu/courses/s216/data/interference.csv")
paired_observed_plot(color)

color_diff <- color %>% 
  mutate(differences = DiffCol-Black)
color_diff %>%
  ggplot(aes(x = differences))+
  geom_boxplot()+
  labs(title="Boxplot of the Difference in Time to Read Words 
       Between Color and Black for College Undergraduates",
       x = "Differences in time to read words (Color - Black)")
```

The following code gives the summary statistics for the pairwise differences.

```{r, echo=TRUE, eval=TRUE, collapse=FALSE}
color_diff %>% 
  summarise(favstats(differences))
```

#### Check theoretical conditions {-}

4.  How do you know the independence condition is met for these data?
\vspace{0.8in}

5. Is the normality condition met to use the theory-based methods for analysis?  Explain your answer.
\vspace{1in}

#### Use statistical inferential methods to draw inferences from the data {-}


To find the standardized statistic for the paired differences we will use the following formula:

$$T = \frac{\bar{x}_d - \mu_0}{SE(\bar{x}_d)},$$
where the standard error of the sample mean difference is:

$$SE(\bar{x}_d)=\frac{s_d}{\sqrt{n}}.$$

6.  Calculate the standard error of the sample mean difference.

\vspace{0.5in}

7.  How many standard errors is the observed mean difference from the null mean difference?

\vspace{0.5in}

To find the p-value we enter the value for the standardized statistic (T = 2.464) into the pt function in R.  If you did not get his answer for question 7, double check your work.  For a single sample or paired data, degrees of freedom are found by subtracting 1 from the sample size.  You should therefore use `df` = $n-1 = 70 - 1 = 69$ and `lower.tail = FALSE` to find the p-value.    

```{r, echo=TRUE, eval=TRUE, collapse=FALSE}
pt(2.464, df=69, lower.tail=FALSE)
```
8.  What does this p-value mean, in the context of the study?  Hint: it is the probability of what...assuming what?
\vspace{1in}

Next we will calculate a theory-based confidence interval.  To calculate a theory-based confidence interval for the paired mean difference, use the following formula:

$$\bar{x}_d\pm t^* \times SE(\bar{x}_d).$$

We will need to find the $t^*$ multiplier using the function `qt()`. The code below will return the 95th percentile of the $t$ distribution with `df` = $n_d - 1 = 70 - 1 = 69$. 

```{r, echo=TRUE, eval=TRUE, collapse=FALSE}
qt(0.95, df = 69, lower.tail=TRUE)
```

```{r tstar, echo = F, fig.cap = "t-distribution with 69 degrees of freedom"}

x <- seq(-4, 4, length=100)
hx<-dt(x, 69)
degf <- 69

plot(x, hx, type="l", lty=1, lwd=3, xlab="x value",
  ylab="Density", main="t Distribution with 69 df")

```

9.  Calculate the margin of error for the true paired mean difference using theory-based methods.

\vspace{0.6in}

10.  Calculate the confidence interval for the true paired mean difference using theory-based methods.

\vspace{0.6in}


11.  Interpret the confidence interval in context of the study.

\vspace{1in}

12.  Write a conclusion to the test in context of the study.
\vspace{0.6in}


<!-- 17.  The abstract states, that the conflicting color stimuli "caused an increase of 2.3 seconds or 5.6% over the normal time for reading the same words printed in black." Is this statement valid? Explain. -->
<!-- \vspace{0.6in} -->



### Take-home messages

1.  In order to use theory-based methods for dependent groups (paired data), the independent observational units and normality conditions must be met.  

2.  A T-score is compared to a $t$-distribution with $n - 1$ df in order to calculate a one-sided p-value. To find a two-sided p-value using theory-based methods we need to multiply the one-sided p-value by 2.  

3.  A $t^*$ multiplier is found by obtaining the bounds of the middle X% (X being the desired confidence level) of a $t$-distribution with $n - 1$ df.


### Additional notes

Use this space to summarize your thoughts and take additional notes on today's activity and material covered

\newpage
