# Exploring Quantitative Data: Exploratory Data Analysis and Hypothesis Testing for a Single Quantitative Variable

## Vocabulary Review and Key Topics

Review the Golden Ticket posted in the resources at the end of the coursepack for a summary of a single quantitative variable.  

### Key topics

Module 6 will introduce exploratory data analysis and hypothesis testing using both simulation-based and theory-based methods for a single quantitative variable.
The **summary measure** for one quantitative variable is the **mean**.
Additionally, we can find the five number summary (min, Q1, median, Q3, max) as well as the sample standard deviation.

* Notation for a sample mean: $\bar{x}$

* Notation for a sample standard deviation: $s$

* Notation for a population mean: $\mu$

* Notation for a population standard deviation: $\sigma$

* Types of plots for a single categorical variable:

    - Histogram
    
    - Boxplot
    
    - Dotplot



### Vocabulary

#### Sample statistics for a single quantitative variable {-}

* **Mean**, $\bar{x}$: the average
$$ 
\bar{x} = \frac{x_1 + x_2 + \cdots + x_n}{n},
$$
where $x_1, x_2, \ldots, x_n$ are the data values and $n$ is the sample size.


* **Median**: value at the 50th percentile; approximately 50\% of data values are at or below the value of the median.

\vspace{1mm}

* **Quartile 1** (lower quartile), $Q_1$: value at the 25th percentile; approximately 25\% of data values are at or below the value of $Q_1$.

\vspace{1mm}

* **Quartile 3** (upper quartile), $Q_3$: value at the 75th percentile; approximately 75\% of data values are at or below the value of $Q_3$.

\newpage

* **Sample standard deviation**, $s$: on average, each value in the data set is $s$ units from the mean of the data set ($\bar{x}$). We will always calculate $s$ using R, but it is calculated using the following formula:
$$
s = \sqrt{\frac{(x_1-\bar{x})^2 + (x_2-\bar{x})^2 + \cdots + (x_n-\bar{x})^2}{n}},
$$
where $x_1, x_2, \ldots, x_n$ are the data values, $\bar{x}$ is the sample mean, and $n$ is the sample size.

* **Interquartile range**: the range of the data between the two quartiles: $IQR = Q_3-Q_1$.

* R code to find the summary statistics for a quantitative variable:

    ```{r, eval=FALSE, echo=TRUE}
    object %>% # Data set piped into...
        summarise(favstats(variable))
    ```

#### Plotting one quantitative variable {-}

* **Histogram**: sorts a quantitative variable into bins of a certain width. R code to create a histogram:

    ```{r, echo=TRUE, eval=FALSE}
    object %>% # Data set piped into...
        ggplot(aes(x = variable)) +   # Name variable to plot
        geom_histogram(binwidth = 10) +  # Create histogram with specified binwidth
        labs(title = "Don't forget to title the plot!", # Title for plot
            x = "x-axis label", # Label for x axis
            y = "y-axis label") # Label for y axis
    ```


* **Boxplot**: plots the values of the five-number summary and shows any outliers in the data set. R code to create a boxplot:

    ```{r, echo=TRUE, eval=FALSE}
    object %>% # Data set piped into...
        ggplot(aes(x = variable)) + # Name variable to plot
        geom_boxplot() + # Create boxplot 
        labs(title = "Don't forget to title the plot!", # Title for plot
            x = "x-axis label", # Label for x axis
            y = "y-axis label") # Label for y axis
    ```

* **Dotplot**: plots each value as a dot along the $x$-axis. R code to create a dotplot:

    ```{r, echo=TRUE, eval=FALSE}
    object %>% # Data set piped into...
        ggplot(aes(x = variable)) + # Name variable to plot
        geom_dotplot() + # Create dotplot 
        labs(title = "Don't forget to title the plot!", # Title for plot
            x = "x-axis label", # Label for x axis
            y = "y-axis label") # Label for y axis
    ```
    
* Four characteristics of a distribution of a single quantitative variable:

    - Shape  (symmetric, skewed left, or skewed right)
    
    - Center 
    
    - Spread
    
    - Outliers?

\newpage

#### Hypothesis testing for a single mean {-}

* **Hypotheses in notation for a single mean**: In the hypotheses below, $\mu_0$ is the **null value**.

$$H_0: \mu = \mu_0$$
$$H_A: \mu\left\{
\begin{array}{ll}
< \\
\ne \\
< \\
\end{array}
\right\}
\mu_0 $$


#### Simulation-based hypothesis testing {-}

* **Conditions necessary to use simulation-based methods for inference  for a single quantitative variable**:

    * **Independence**: observational units must be independent of one another.

* **Simulation-based methods to create the null distribution**: R code to use for simulation-based methods for one quantitative variable to find the p-value, `one_mean_test` (from the `catstats` package), is shown below. Review the comments (instructions after the #) to see what each should be entered for each line of code.

    ```{r, eval=FALSE, echo=TRUE}
    one_mean_test(object$variable,#Enter the object name and variable
              null_value = xx, #Enter the null value for the study
              summary_measure = "mean",  #Can choose between mean or median
              shift = xx, #Difference between the null value and the sample mean
              as_extreme_as = xx, #Value of the summary statistic
              direction = "xx", #Specify direction of alternative hypothesis
              number_repetitions = 10000)
    ```

#### Theory-based hypothesis testing {-}

* Theory-based methods should give the same results as simulation-based methods if conditions are met. For a single quantitative variable, conditions are met if either the data themselves follow a normal distribution or if the sample size is large enough. We call this the "normality condition."

* **Conditions for the sampling distribution of $\bar{x}$ to follow an approximate normal distribution**:

    * **Independence**: the sampleâ€™s observations are independent, e.g., are from a simple random sample. (*Remember*: This also must be true to use simulation methods!)

     * **Normality Condition**: either the sample observations come from a normally distributed population or we have a large enough sample size.  To check this condition, use the following rules of thumb:
     
         - $n < 30$: The distribution of the sample must be approximately normal with no outliers.
         
         - $30 \le n < 100$: We can relax the condition a little; the distribution of the sample must have no extreme outliers or skewness.
         
         - $n \ge 100$: Can assume the sampling distribution of $\bar{x}$ is nearly normal, even if the underlying distribution of individual observations is not.
         
* **t-distribution**: a theoretical distribution that is bell-shaped with mean zero. Its degrees of freedom determine the variability of the distribution. For very large degrees of freedom, the $t$-distribution is close to a standard normal distribution. For a single quantitative variable, the degrees of freedom are calculated by subtracting one from the sample size: $n-1$. A $t$-distribution with $n-1$ degrees of freedom is denoted by: $t_{n-1}$.

* **Standard error of the sample mean**: measures the how far each possible sample mean is from the true mean, on average, and is calculated using the formula below:
$$SE(\bar{x})=\frac{s}{\sqrt{n}}$$
    where $s$ is the sample standard deviation. 
    
    * For inference involving means, the formula for the standard error will be the same for both hypothesis tests and confidence intervals (unlike inference involving proportions, where the standard error for a hypothesis test used the null value in the calculation).

* **Standardized sample mean**: standardized statistic for a single quantitative variable calculated using:
$$
T = \frac{\bar{x} - \mu_0}{SE(\bar{x})},
$$
    If the conditions for the sampling distribution of $\bar{x}$ to follow an approximate normal distribution are met, and if the true value of $\mu$ is equal to the null value of $\mu_0$, the standardized sample mean, $T$, will have an approximate $t$-distribution with $n-1$ degrees of freedom.

* The theory-based **p-value** for hypothesis testing involving means can be found in R by using the `pt` function to find the probability of the observed standardized statistic or one more extreme (in the direction of $H_A$). This probability is the area under a _$t$-distribution with the appropriate degrees of freedom_ at or more extreme than the observed standardized statistic.

    * `pt` will give you a p-value using the $t$-distribution with a given degrees of freedom (enter for `yy`). For a single mean, `df` = $n - 1$.
    
    * Enter the value of the standardized statistic for `xx`

    * If a "greater than" alternative, change `lower.tail = TRUE` to `FALSE`.
    
    * If a two-sided test, multiply by 2.
    
    ```{r, eval = FALSE, echo=TRUE}
    pt(xx, df = yy, lower.tail=TRUE)
    ```




\newpage
